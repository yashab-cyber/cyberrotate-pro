# Automation and Scheduling

This guide covers automation features and scheduling capabilities in CyberRotate Pro, helping you set up automated IP rotation workflows and scheduled tasks.

## ðŸ“‹ Table of Contents

1. [Automation Overview](#automation-overview)
2. [Rotation Scheduling](#rotation-scheduling)
3. [Conditional Automation](#conditional-automation)
4. [Workflow Automation](#workflow-automation)
5. [Event-Driven Actions](#event-driven-actions)
6. [Backup and Recovery Automation](#backup-and-recovery-automation)
7. [Monitoring Automation](#monitoring-automation)
8. [Custom Scripts](#custom-scripts)
9. [Integration with External Systems](#integration-with-external-systems)
10. [Advanced Automation Patterns](#advanced-automation-patterns)

---

## ðŸ¤– Automation Overview

CyberRotate Pro provides comprehensive automation capabilities to reduce manual intervention and ensure consistent operation.

### Key Automation Features

- **Scheduled Rotations**: Time-based IP rotation
- **Conditional Triggers**: Event-based automation
- **Workflow Orchestration**: Multi-step automated processes
- **Health Monitoring**: Automated system checks
- **Recovery Procedures**: Automatic failure recovery
- **Maintenance Tasks**: Scheduled cleanup and optimization

### Automation Benefits

```yaml
benefits:
  reliability: "99.9% uptime through automated monitoring"
  efficiency: "75% reduction in manual tasks"
  consistency: "Standardized processes and procedures"
  scalability: "Handle increased load automatically"
  cost_savings: "Reduced operational overhead"
  compliance: "Automated audit trails and logging"
```

---

## â° Rotation Scheduling

### Basic Scheduling

Configure automatic IP rotation based on time intervals:

```json
{
  "rotation_schedule": {
    "enabled": true,
    "type": "interval",
    "interval": "15m",
    "jitter": "2m",
    "max_attempts": 3,
    "fallback_providers": ["backup_vpn", "proxy_pool"]
  }
}
```

### Advanced Scheduling

```yaml
advanced_schedule:
  # Business hours rotation
  business_hours:
    schedule: "*/10 * 9-17 * * MON-FRI"
    rotation_type: "vpn"
    providers: ["nordvpn", "expressvpn"]
    countries: ["US", "CA", "UK"]
  
  # After hours rotation
  after_hours:
    schedule: "*/30 * 18-8 * * *"
    rotation_type: "proxy"
    providers: ["proxymesh", "smartproxy"]
    countries: ["ANY"]
  
  # Weekend schedule
  weekend:
    schedule: "*/60 * * * * SAT,SUN"
    rotation_type: "auto"
    providers: ["any"]
    countries: ["US", "EU"]
```

### Cron-based Scheduling

```python
from crontab import CronTab

class RotationScheduler:
    def __init__(self):
        self.cron = CronTab(user=True)
    
    def schedule_rotation(self, schedule_expr, rotation_config):
        """Schedule rotation using cron expression"""
        
        job = self.cron.new(command=f'cyberrotate rotate --config "{rotation_config}"')
        job.setall(schedule_expr)
        
        if job.is_valid():
            self.cron.write()
            return {"status": "scheduled", "job_id": str(job)}
        else:
            return {"status": "error", "message": "Invalid cron expression"}
    
    def list_scheduled_jobs(self):
        """List all scheduled rotation jobs"""
        jobs = []
        for job in self.cron:
            if 'cyberrotate' in job.command:
                jobs.append({
                    "schedule": str(job.slices),
                    "command": job.command,
                    "enabled": job.is_enabled()
                })
        return jobs

# Usage
scheduler = RotationScheduler()

# Rotate every 15 minutes during business hours
scheduler.schedule_rotation(
    "*/15 9-17 * * 1-5",
    {"type": "vpn", "provider": "nordvpn", "country": "US"}
)

# Rotate every hour on weekends
scheduler.schedule_rotation(
    "0 * * * 6,0",
    {"type": "proxy", "provider": "proxymesh", "country": "ANY"}
)
```

---

## ðŸŽ¯ Conditional Automation

### Trigger-based Automation

Set up automated actions based on specific conditions:

```json
{
  "conditional_rules": [
    {
      "name": "High Latency Recovery",
      "trigger": {
        "condition": "latency > 200ms",
        "duration": "5m"
      },
      "actions": [
        {"type": "rotate_ip", "immediate": true},
        {"type": "switch_provider", "preferred": "expressvpn"},
        {"type": "notify", "channels": ["email", "slack"]}
      ]
    },
    {
      "name": "Connection Failure Recovery",
      "trigger": {
        "condition": "connection_failures >= 3",
        "window": "10m"
      },
      "actions": [
        {"type": "switch_protocol", "protocol": "tcp"},
        {"type": "change_location", "strategy": "nearest"},
        {"type": "restart_service", "component": "vpn_client"}
      ]
    },
    {
      "name": "Bandwidth Throttling Detection",
      "trigger": {
        "condition": "download_speed < 10Mbps",
        "baseline": "average_30d",
        "threshold": 0.3
      },
      "actions": [
        {"type": "rotate_ip"},
        {"type": "test_speed", "samples": 3},
        {"type": "log_incident", "severity": "warning"}
      ]
    }
  ]
}
```

### Smart Automation Engine

```python
class SmartAutomationEngine:
    def __init__(self):
        self.rules = []
        self.metrics_history = {}
        self.ml_model = None
    
    def add_rule(self, rule):
        """Add automation rule"""
        self.rules.append(rule)
    
    def evaluate_conditions(self, current_metrics):
        """Evaluate all conditions and trigger actions"""
        triggered_actions = []
        
        for rule in self.rules:
            if self.check_condition(rule['trigger'], current_metrics):
                triggered_actions.extend(rule['actions'])
        
        return triggered_actions
    
    def check_condition(self, trigger, metrics):
        """Check if trigger condition is met"""
        condition = trigger['condition']
        
        # Parse condition (simplified example)
        if 'latency >' in condition:
            threshold = float(condition.split('>')[-1].strip().replace('ms', ''))
            return metrics.get('latency', 0) > threshold
        
        elif 'connection_failures >=' in condition:
            threshold = int(condition.split('>='[-1].strip()))
            return metrics.get('connection_failures', 0) >= threshold
        
        return False
    
    def execute_actions(self, actions):
        """Execute triggered actions"""
        results = []
        
        for action in actions:
            try:
                result = self.execute_single_action(action)
                results.append(result)
            except Exception as e:
                results.append({"status": "error", "message": str(e)})
        
        return results
    
    def execute_single_action(self, action):
        """Execute single automation action"""
        action_type = action['type']
        
        if action_type == 'rotate_ip':
            return self.rotate_ip_action(action)
        elif action_type == 'switch_provider':
            return self.switch_provider_action(action)
        elif action_type == 'notify':
            return self.notify_action(action)
        # Add more action types as needed
```

---

## ðŸ”„ Workflow Automation

### Multi-step Workflows

Define complex automation workflows with multiple steps:

```yaml
workflows:
  daily_maintenance:
    name: "Daily Maintenance Workflow"
    schedule: "0 2 * * *"  # 2 AM daily
    steps:
      - name: "Health Check"
        action: "system_health_check"
        timeout: "5m"
        
      - name: "Cleanup Logs"
        action: "cleanup_old_logs"
        parameters:
          retention_days: 30
        
      - name: "Update Provider Lists"
        action: "update_provider_servers"
        parameters:
          providers: ["nordvpn", "expressvpn"]
        
      - name: "Test Connections"
        action: "test_all_providers"
        parameters:
          timeout: "30s"
          max_concurrent: 5
        
      - name: "Generate Report"
        action: "generate_maintenance_report"
        parameters:
          format: "email"
          recipients: ["admin@company.com"]

  incident_response:
    name: "Incident Response Workflow"
    trigger: "manual"
    steps:
      - name: "Assess Situation"
        action: "collect_diagnostics"
        
      - name: "Attempt Recovery"
        action: "auto_recovery"
        parameters:
          max_attempts: 3
        
      - name: "Escalate if Needed"
        condition: "recovery_failed"
        action: "send_alert"
        parameters:
          urgency: "high"
          channels: ["email", "sms", "slack"]
```

### Workflow Engine

```python
import asyncio
from typing import List, Dict, Any

class WorkflowEngine:
    def __init__(self):
        self.workflows = {}
        self.active_executions = {}
    
    def register_workflow(self, workflow_config):
        """Register a new workflow"""
        name = workflow_config['name']
        self.workflows[name] = workflow_config
    
    async def execute_workflow(self, workflow_name, context=None):
        """Execute a workflow"""
        if workflow_name not in self.workflows:
            raise ValueError(f"Workflow {workflow_name} not found")
        
        workflow = self.workflows[workflow_name]
        execution_id = f"{workflow_name}_{int(time.time())}"
        
        self.active_executions[execution_id] = {
            "workflow": workflow_name,
            "status": "running",
            "started_at": time.time(),
            "steps_completed": 0,
            "total_steps": len(workflow['steps'])
        }
        
        try:
            results = []
            for i, step in enumerate(workflow['steps']):
                # Check step condition if exists
                if 'condition' in step and not self.check_condition(step['condition'], context):
                    continue
                
                # Execute step
                result = await self.execute_step(step, context)
                results.append(result)
                
                # Update execution status
                self.active_executions[execution_id]['steps_completed'] = i + 1
                
                # Handle step failure
                if result.get('status') == 'failed':
                    if step.get('continue_on_failure', False):
                        continue
                    else:
                        raise Exception(f"Step {step['name']} failed: {result.get('error')}")
            
            self.active_executions[execution_id]['status'] = 'completed'
            return {"status": "success", "results": results}
            
        except Exception as e:
            self.active_executions[execution_id]['status'] = 'failed'
            self.active_executions[execution_id]['error'] = str(e)
            return {"status": "failed", "error": str(e)}
    
    async def execute_step(self, step, context):
        """Execute a single workflow step"""
        action = step['action']
        parameters = step.get('parameters', {})
        timeout = step.get('timeout', '30s')
        
        try:
            # Execute action with timeout
            result = await asyncio.wait_for(
                self.execute_action(action, parameters, context),
                timeout=self.parse_timeout(timeout)
            )
            return {"status": "success", "result": result}
            
        except asyncio.TimeoutError:
            return {"status": "failed", "error": "Step timeout"}
        except Exception as e:
            return {"status": "failed", "error": str(e)}
```

---

## ðŸ“¡ Event-Driven Actions

### Event System

Set up event-driven automation based on system events:

```python
class EventDrivenAutomation:
    def __init__(self):
        self.event_handlers = {}
        self.event_queue = asyncio.Queue()
    
    def register_handler(self, event_type, handler_func):
        """Register event handler"""
        if event_type not in self.event_handlers:
            self.event_handlers[event_type] = []
        self.event_handlers[event_type].append(handler_func)
    
    async def emit_event(self, event_type, event_data):
        """Emit an event"""
        event = {
            "type": event_type,
            "data": event_data,
            "timestamp": time.time()
        }
        await self.event_queue.put(event)
    
    async def process_events(self):
        """Process events from queue"""
        while True:
            try:
                event = await self.event_queue.get()
                await self.handle_event(event)
            except Exception as e:
                print(f"Error processing event: {e}")
    
    async def handle_event(self, event):
        """Handle a single event"""
        event_type = event['type']
        
        if event_type in self.event_handlers:
            for handler in self.event_handlers[event_type]:
                try:
                    await handler(event['data'])
                except Exception as e:
                    print(f"Error in event handler: {e}")

# Event handlers
async def handle_connection_failure(event_data):
    """Handle connection failure event"""
    print(f"Connection failed: {event_data}")
    
    # Attempt automatic recovery
    await rotate_to_backup_server()
    await send_alert("Connection failure detected, switched to backup")

async def handle_ip_leak_detected(event_data):
    """Handle IP leak detection event"""
    print(f"IP leak detected: {event_data}")
    
    # Immediate actions
    await emergency_disconnect()
    await enable_kill_switch()
    await send_critical_alert("IP leak detected - emergency disconnect activated")

# Usage
automation = EventDrivenAutomation()
automation.register_handler("connection_failure", handle_connection_failure)
automation.register_handler("ip_leak_detected", handle_ip_leak_detected)

# Start event processing
asyncio.create_task(automation.process_events())
```

### Event Configuration

```json
{
  "event_automation": {
    "connection_events": {
      "connection_established": [
        {"action": "log_event", "level": "info"},
        {"action": "update_status", "status": "connected"}
      ],
      "connection_lost": [
        {"action": "log_event", "level": "warning"},
        {"action": "attempt_reconnect", "max_attempts": 3},
        {"action": "notify_admin", "method": "email"}
      ],
      "connection_slow": [
        {"action": "test_speed", "samples": 3},
        {"action": "rotate_if_slow", "threshold": "10Mbps"}
      ]
    },
    "security_events": {
      "ip_leak_detected": [
        {"action": "emergency_disconnect", "immediate": true},
        {"action": "enable_kill_switch"},
        {"action": "send_alert", "priority": "critical"}
      ],
      "dns_leak_detected": [
        {"action": "switch_dns", "dns": "custom"},
        {"action": "test_dns_leak"},
        {"action": "log_incident", "severity": "medium"}
      ]
    }
  }
}
```

---

## ðŸ’¾ Backup and Recovery Automation

### Automated Backups

```yaml
backup_automation:
  configuration_backup:
    schedule: "0 3 * * *"  # Daily at 3 AM
    include:
      - "config/*.json"
      - "config/*.yaml" 
      - "profiles/*.conf"
    exclude:
      - "*.log"
      - "temp/*"
    destination: "backups/config"
    retention: 30  # days
    compression: true
    encryption: true
    
  analytics_backup:
    schedule: "0 2 * * 0"  # Weekly on Sunday at 2 AM
    include:
      - "analytics.db"
      - "reports/*"
    destination: "backups/analytics"
    retention: 90  # days
    compression: true
    
  full_system_backup:
    schedule: "0 1 1 * *"  # Monthly on 1st at 1 AM
    include:
      - "config/*"
      - "analytics.db"
      - "logs/*.log"
      - "profiles/*"
    destination: "backups/full"
    retention: 365  # days
    compression: true
    encryption: true
```

### Recovery Procedures

```python
class AutoRecovery:
    def __init__(self):
        self.recovery_procedures = {
            "connection_failure": self.recover_connection,
            "configuration_corruption": self.recover_configuration,
            "service_crash": self.recover_service,
            "disk_full": self.recover_disk_space
        }
    
    async def auto_recover(self, issue_type, context):
        """Attempt automatic recovery"""
        if issue_type in self.recovery_procedures:
            procedure = self.recovery_procedures[issue_type]
            return await procedure(context)
        else:
            return {"status": "no_recovery_available", "issue": issue_type}
    
    async def recover_connection(self, context):
        """Recover from connection issues"""
        steps = [
            ("Test current connection", self.test_connection),
            ("Try different server", self.switch_server),
            ("Change protocol", self.switch_protocol),
            ("Use backup provider", self.switch_provider),
            ("Reset network interface", self.reset_network)
        ]
        
        for step_name, step_func in steps:
            try:
                result = await step_func(context)
                if result.get("success"):
                    return {
                        "status": "recovered",
                        "method": step_name,
                        "details": result
                    }
            except Exception as e:
                print(f"Recovery step '{step_name}' failed: {e}")
                continue
        
        return {"status": "recovery_failed", "attempted_steps": len(steps)}
    
    async def recover_configuration(self, context):
        """Recover from configuration corruption"""
        try:
            # Restore from latest backup
            backup_path = self.find_latest_backup("config")
            if backup_path:
                self.restore_backup(backup_path)
                return {"status": "recovered", "method": "backup_restore"}
            
            # Use default configuration
            self.load_default_config()
            return {"status": "recovered", "method": "default_config"}
            
        except Exception as e:
            return {"status": "recovery_failed", "error": str(e)}
```

---

## ðŸ“Š Monitoring Automation

### Health Check Automation

```python
class HealthCheckAutomation:
    def __init__(self):
        self.checks = [
            ("VPN Connection", self.check_vpn_connection),
            ("DNS Resolution", self.check_dns_resolution),
            ("IP Leak Test", self.check_ip_leak),
            ("Speed Test", self.check_connection_speed),
            ("Provider Health", self.check_provider_health)
        ]
        self.check_interval = 300  # 5 minutes
    
    async def run_continuous_checks(self):
        """Run health checks continuously"""
        while True:
            try:
                results = await self.run_all_checks()
                await self.process_health_results(results)
                await asyncio.sleep(self.check_interval)
            except Exception as e:
                print(f"Error in health checks: {e}")
                await asyncio.sleep(60)  # Wait 1 minute before retrying
    
    async def run_all_checks(self):
        """Run all health checks"""
        results = {}
        
        for check_name, check_func in self.checks:
            try:
                start_time = time.time()
                result = await check_func()
                end_time = time.time()
                
                results[check_name] = {
                    "status": "passed" if result.get("success") else "failed",
                    "duration": end_time - start_time,
                    "details": result
                }
            except Exception as e:
                results[check_name] = {
                    "status": "error",
                    "error": str(e)
                }
        
        return results
    
    async def process_health_results(self, results):
        """Process health check results and take actions"""
        failed_checks = [name for name, result in results.items() 
                        if result['status'] != 'passed']
        
        if failed_checks:
            # Determine severity
            critical_checks = ['VPN Connection', 'IP Leak Test']
            is_critical = any(check in critical_checks for check in failed_checks)
            
            # Take appropriate action
            if is_critical:
                await self.handle_critical_failure(failed_checks, results)
            else:
                await self.handle_minor_failure(failed_checks, results)
        
        # Log results
        await self.log_health_results(results)
```

### Automated Alerts

```json
{
  "alert_automation": {
    "channels": {
      "email": {
        "enabled": true,
        "smtp_server": "smtp.gmail.com",
        "recipients": ["admin@company.com", "alerts@company.com"]
      },
      "slack": {
        "enabled": true,
        "webhook_url": "https://hooks.slack.com/services/...",
        "channel": "#alerts"
      },
      "webhook": {
        "enabled": true,
        "url": "https://api.company.com/alerts",
        "headers": {"Authorization": "Bearer token"}
      }
    },
    "rules": [
      {
        "name": "Critical Service Failure",
        "condition": "service_status == 'failed'",
        "channels": ["email", "slack", "webhook"],
        "throttle": "5m"
      },
      {
        "name": "Performance Degradation",
        "condition": "avg_speed < 10Mbps AND duration > 10m",
        "channels": ["slack"],
        "throttle": "15m"
      },
      {
        "name": "High Error Rate",
        "condition": "error_rate > 5% AND window == '1h'",
        "channels": ["email"],
        "throttle": "30m"
      }
    ]
  }
}
```

---

## ðŸ”§ Custom Scripts

### Script Framework

```python
class AutomationScript:
    def __init__(self, name, description=""):
        self.name = name
        self.description = description
        self.parameters = {}
        self.execution_log = []
    
    def add_parameter(self, name, param_type, default_value=None, required=True):
        """Add script parameter"""
        self.parameters[name] = {
            "type": param_type,
            "default": default_value,
            "required": required
        }
    
    async def execute(self, **kwargs):
        """Execute the script"""
        # Validate parameters
        for param_name, param_config in self.parameters.items():
            if param_config["required"] and param_name not in kwargs:
                raise ValueError(f"Required parameter '{param_name}' missing")
        
        # Set defaults
        for param_name, param_config in self.parameters.items():
            if param_name not in kwargs and param_config["default"] is not None:
                kwargs[param_name] = param_config["default"]
        
        # Execute script
        start_time = time.time()
        try:
            result = await self.run(**kwargs)
            execution_time = time.time() - start_time
            
            self.execution_log.append({
                "timestamp": start_time,
                "duration": execution_time,
                "status": "success",
                "result": result
            })
            
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            
            self.execution_log.append({
                "timestamp": start_time,
                "duration": execution_time,
                "status": "error",
                "error": str(e)
            })
            
            raise
    
    async def run(self, **kwargs):
        """Override this method in subclasses"""
        raise NotImplementedError("Subclasses must implement run() method")

# Example custom script
class ServerOptimizationScript(AutomationScript):
    def __init__(self):
        super().__init__("Server Optimization", "Optimize server selection based on performance")
        self.add_parameter("test_duration", int, 30, True)
        self.add_parameter("min_speed", float, 50.0, False)
        self.add_parameter("max_latency", float, 100.0, False)
    
    async def run(self, **kwargs):
        test_duration = kwargs["test_duration"]
        min_speed = kwargs.get("min_speed", 50.0)
        max_latency = kwargs.get("max_latency", 100.0)
        
        # Get available servers
        servers = await self.get_available_servers()
        
        # Test each server
        results = []
        for server in servers:
            performance = await self.test_server_performance(server, test_duration)
            if (performance["speed"] >= min_speed and 
                performance["latency"] <= max_latency):
                results.append({
                    "server": server,
                    "performance": performance,
                    "score": self.calculate_score(performance)
                })
        
        # Sort by score and return best servers
        results.sort(key=lambda x: x["score"], reverse=True)
        
        return {
            "best_servers": results[:5],
            "total_tested": len(servers),
            "qualifying_servers": len(results)
        }
```

---

## ðŸ”— Integration with External Systems

### API Integrations

```python
class ExternalIntegrations:
    def __init__(self):
        self.integrations = {}
    
    def register_integration(self, name, integration):
        """Register external integration"""
        self.integrations[name] = integration
    
    async def trigger_webhook(self, webhook_url, event_data):
        """Trigger external webhook"""
        async with aiohttp.ClientSession() as session:
            async with session.post(webhook_url, json=event_data) as response:
                return await response.json()
    
    async def update_monitoring_system(self, metrics):
        """Update external monitoring system"""
        if "prometheus" in self.integrations:
            await self.integrations["prometheus"].push_metrics(metrics)
        
        if "datadog" in self.integrations:
            await self.integrations["datadog"].send_metrics(metrics)
    
    async def sync_with_cmdb(self, asset_data):
        """Sync with Configuration Management Database"""
        if "cmdb" in self.integrations:
            await self.integrations["cmdb"].update_asset(asset_data)

# Example integration
class PrometheusIntegration:
    def __init__(self, gateway_url):
        self.gateway_url = gateway_url
    
    async def push_metrics(self, metrics):
        """Push metrics to Prometheus Pushgateway"""
        payload = self.format_prometheus_metrics(metrics)
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.gateway_url}/metrics/job/cyberrotate",
                data=payload,
                headers={"Content-Type": "text/plain"}
            ) as response:
                return response.status == 200
```

### Database Synchronization

```python
class DatabaseSync:
    def __init__(self, external_db_config):
        self.external_db = self.connect_external_db(external_db_config)
    
    async def sync_usage_data(self):
        """Sync usage data with external database"""
        local_data = await self.get_local_usage_data()
        
        for record in local_data:
            await self.external_db.upsert("usage_records", record)
    
    async def sync_provider_status(self):
        """Sync provider status with external systems"""
        provider_status = await self.get_provider_status()
        
        await self.external_db.bulk_update("provider_status", provider_status)
```

---

## ðŸš€ Advanced Automation Patterns

### Machine Learning Automation

```python
class MLAutomation:
    def __init__(self):
        self.models = {}
        self.training_data = []
    
    def train_optimization_model(self, historical_data):
        """Train model to optimize server selection"""
        from sklearn.ensemble import RandomForestRegressor
        
        # Prepare features and targets
        features = self.extract_features(historical_data)
        targets = self.extract_targets(historical_data)
        
        # Train model
        model = RandomForestRegressor(n_estimators=100)
        model.fit(features, targets)
        
        self.models["server_optimization"] = model
    
    def predict_optimal_server(self, current_conditions):
        """Predict optimal server based on current conditions"""
        if "server_optimization" not in self.models:
            return None
        
        model = self.models["server_optimization"]
        features = self.prepare_features(current_conditions)
        
        prediction = model.predict([features])
        return prediction[0]
    
    async def adaptive_rotation(self):
        """Implement adaptive rotation based on ML predictions"""
        current_conditions = await self.gather_current_conditions()
        optimal_server = self.predict_optimal_server(current_conditions)
        
        if optimal_server:
            await self.rotate_to_server(optimal_server)
```

### Chaos Engineering Automation

```python
class ChaosEngineering:
    def __init__(self):
        self.experiments = []
    
    def register_experiment(self, experiment):
        """Register chaos experiment"""
        self.experiments.append(experiment)
    
    async def run_random_experiment(self):
        """Run random chaos experiment"""
        if not self.experiments:
            return
        
        experiment = random.choice(self.experiments)
        await self.execute_experiment(experiment)
    
    async def execute_experiment(self, experiment):
        """Execute chaos experiment"""
        print(f"Starting chaos experiment: {experiment['name']}")
        
        # Record baseline metrics
        baseline = await self.collect_baseline_metrics()
        
        # Introduce chaos
        await self.introduce_chaos(experiment)
        
        # Monitor system behavior
        behavior = await self.monitor_behavior(experiment['duration'])
        
        # Restore normal operation
        await self.restore_normal_operation(experiment)
        
        # Analyze results
        results = await self.analyze_experiment_results(baseline, behavior)
        
        return results

# Example chaos experiments
network_latency_experiment = {
    "name": "Network Latency Injection",
    "type": "network",
    "action": "inject_latency",
    "parameters": {"delay": "100ms", "jitter": "10ms"},
    "duration": 300,  # 5 minutes
    "target": "vpn_connection"
}

provider_failure_experiment = {
    "name": "Provider Failure Simulation",
    "type": "provider",
    "action": "block_provider",
    "parameters": {"provider": "primary_vpn"},
    "duration": 180,  # 3 minutes
    "expected_behavior": "automatic_failover"
}
```

---

## ðŸ“– Configuration Examples

### Complete Automation Configuration

```yaml
automation_config:
  enabled: true
  log_level: "INFO"
  
  # Scheduling
  scheduling:
    timezone: "UTC"
    max_concurrent_jobs: 5
    job_timeout: 3600  # 1 hour
    
  # Event processing
  events:
    queue_size: 1000
    processing_threads: 4
    retry_attempts: 3
    
  # Monitoring
  monitoring:
    health_check_interval: 300
    metrics_collection_interval: 60
    alert_throttling: 300
    
  # Recovery
  recovery:
    auto_recovery_enabled: true
    max_recovery_attempts: 3
    recovery_timeout: 600
    
  # Integration
  integrations:
    webhook_timeout: 30
    external_api_timeout: 60
    retry_backoff: "exponential"
```

---

## ðŸ“– Additional Resources

- **Configuration Guide**: See [03-configuration.md](03-configuration.md) for automation settings
- **API Reference**: Check [06-api-reference.md](06-api-reference.md) for automation APIs
- **Monitoring**: Visit [12-analytics.md](12-analytics.md) for monitoring automation
- **Troubleshooting**: Review [14-troubleshooting.md](14-troubleshooting.md) for automation issues

---

**Automation Best Practices:**

1. Start with simple time-based schedules
2. Implement comprehensive error handling
3. Use conditional automation for intelligent responses
4. Monitor automation performance and effectiveness
5. Test automation workflows in staging environment
6. Keep automation scripts simple and maintainable

---

*This guide is part of the CyberRotate Pro manual. For more information, visit the [main manual page](README.md).*
